<!doctype html>
<html>
  <head>
  	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-54097643-2"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());

	  gtag('config', 'UA-54097643-2');
	</script>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Sujoy Paul</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1 style="text-align:center;">Sujoy Paul</h1>
        <h1 style="text-align:center;"><img src="my_pic.png" height="200" align="middle"></h1>
        <p style="text-align:center;"><strong>Email</strong>: spaul003@ucr.edu</p>
        <p style="text-align:center;"><strong> <a href="CV.pdf" target="_blank">CV</a> | 
                                               <a href="https://scholar.google.com/citations?user=Iq8BQUYAAAAJ&hl" target="_blank">Scholar</a> | 
                                               <a href="https://github.com/sujoyp" target="_blank">GitHub</a> <br>
                                               <a href="https://www.linkedin.com/in/paulsujoy" target="_blank">LinkedIn</a> |
                                               <a href="https://www.youtube.com/channel/UCBj6P5k3YMKSoPPn6I0dKUQ" target="_blank">YouTube</a>  |
                                               <a href="https://www.flickr.com/photos/193363903@N05/" target="_blank">Photography</a></strong> </p>
        <br>
        <!-- <p style="font-size:20px;text-align:center;">News</p>
        <ul>
        	<li><p style="text-align:justify;">Work on multi-source domain adaptation without source data got accepted at CVPR '21 as Oral</p></li>
    	</ul> -->
<!--     	<dl>
  			<dt>News</dt>
  			<dd> black hot drink</dd>
  			<dt>Milk</dt>
  			<dd>- white cold drink</dd>
		</dl> -->
		<br>
		<strong>News</strong>
    	<dl>
			<li>1 paper at NeurIPS '24</li>
			<li>1 paper at ECCV '24</li>
    		<li>Work got <a href="https://youtu.be/lCFbbOgsm9I?t=1843" target="_blank">featured</a> at Google for India and major newspapers</li>
        </dl>
      </header>
      <section>
        <h2 style="margin-bottom:10px">About</h2>
        <p style="margin-bottom:25px">I am currently a senior research scientist at <a href="https://deepmind.google/" target="_blank">Google DeepMind</a>, working on computer vision and machine learning. Prior to that I completed my PhD from <a href="https://www.ucr.edu/" target="_blank">UC Riverside</a>, advised by <a href="https://vcg.engr.ucr.edu/amit" target="_blank">Amit K Roy-Chowdhury</a>. During my PhD I also spend three summers at <a href="http://www.nec-labs.com/research-departments/media-analytics/media-analytics-home" target="_blank">NEC Labs</a>, <a href="https://www.merl.com/" target="_blank">MERL</a> and <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-india/" target="_blank">Microsoft Research</a>.</p>

        <h2 style="margin-bottom:10px"> Research Interests </h2>
        <p style="margin-bottom:25px">My research interests lie in learning problems in computer vision and robotics using limited human supervision. In the long run, I am interested in developing algorithms which can be learned with low supervision, be generalizable, robust, just like humans, and help in our everyday life. </p>

        <h2 style="margin-bottom:10px"> Selected Publications </h2>

            <td style="padding:10px;width:100%;vertical-align:baseline">
              <p style="font-size:15px;margin-bottom:0;">
                <papertitle><strong>Mixture of Nested Experts: Adaptive Processing of Visual Tokens</strong></papertitle>, NeurIPS '24
              </p>
              <p style="font-size:13px;margin-bottom:0;">Gagan Jain*, Nidhi Hegde, Aditya Kusupati, Arsha Nagrani, Shyamal Buch, Prateek Jain, Anurag Arnab, <strong>Sujoy Paul*</strong></p>
              <a style="font-size:13px" href="https://arxiv.org/pdf/2407.19985" target="_blank">paper </a> 
              <br> <br>
            </td>

            <td style="padding:10px;width:100%;vertical-align:baseline">
              <p style="font-size:15px;margin-bottom:0;">
                <papertitle><strong>LookupViT: Compressing visual information to a limited number of tokens</strong></papertitle>, ECCV '24
              </p>
              <p style="font-size:13px;margin-bottom:0;">Rajat Koner, Gagan Jain, Prateek Jain, Volker Tresp, <strong>Sujoy Paul</strong></p>
              <a style="font-size:13px" href="https://arxiv.org/pdf/2407.12753" target="_blank">paper </a> 
              <br> <br>
            </td>

            <td style="padding:10px;width:100%;vertical-align:baseline">
              <p style="font-size:15px;margin-bottom:0;">
                <papertitle><strong>Test-time adaptation with slot-centric models</strong></papertitle>, ICML '23
              </p>
              <p style="font-size:13px;margin-bottom:0;">Mihir Prabhudesai, <strong>Sujoy Paul</strong>, Sjoerd van Steenkiste, Mehdi Sajjadi, Anirudh Goyal, Deepak Pathak, Katerina Fragkiadaki, Gaurav Aggarwal, Thomas Kipf</p>
              <a style="font-size:13px" href="https://arxiv.org/pdf/2203.11194.pdf" target="_blank">paper </a> 
              <br> <br>
            </td>

            <td style="padding:10px;width:100%;vertical-align:baseline">
              <p style="font-size:15px;margin-bottom:0;">
                <papertitle><strong>Weakly supervised information extraction from inscrutable handwritten document images</strong></papertitle>, ICDAR '23
              </p>
              <p style="font-size:13px;margin-bottom:0;"><strong>Sujoy Paul</strong>, Gagan Madan, Akankshya Mishra, Narayan Hegde, Pradeep Kumar, Gaurav Aggarwal</p>
              <a style="font-size:13px" href="https://arxiv.org/pdf/2306.06823.pdf" target="_blank">paper </a> 
              <br> <br>
            </td>
	      
            <td style="padding:10px;width:100%;vertical-align:baseline">
              <p style="font-size:15px;margin-bottom:0;">
                <papertitle><strong>SITA: Single Image Test-time Adaptation</strong></papertitle>, CVPR-W '23
              </p>
              <p style="font-size:13px;margin-bottom:0;">Ansh Khurana, <strong>Sujoy Paul</strong>, Piyush Rai, Soma Biswas, Gaurav Aggarwal</p>
              <a style="font-size:13px" href="https://arxiv.org/pdf/2112.02355.pdf" target="_blank">paper </a> 
              <br> <br>
            </td>

            <td style="padding:10px;width:100%;vertical-align:baseline">
              <p style="font-size:15px;margin-bottom:0;">
                <papertitle><strong>Novel Class Discovery without Forgetting</strong></papertitle>, ECCV '22
              </p>
              <p style="font-size:13px;margin-bottom:0;">KJ Joseph, <strong>Sujoy Paul</strong>, Gaurav Aggarwal, Soma Biswas, Piyush Rai, Kai Han, Vineeth Balasubramanian</p>
              <a style="font-size:13px" href="https://arxiv.org/pdf/2207.10659.pdf" target="_blank">paper </a> 
              <br> <br>
            </td>

            <td style="padding:10px;width:100%;vertical-align:baseline">
              <p style="font-size:15px;margin-bottom:0;">
                <papertitle><strong>Unsupervised Adaptation of Semantic Segmentation Models without Source Data</strong></papertitle>, ICML-W '22
              </p>
              <p style="font-size:13px;margin-bottom:0;"><strong>Sujoy Paul</strong>, Ansh Khurana, Gaurav Aggarwal</p>
              <a style="font-size:13px" href="https://arxiv.org/pdf/2112.02359.pdf" target="_blank">paper </a> 
              <br> <br>
            </td>

            <td style="padding:10px;width:100%;vertical-align:baseline">
              <p style="font-size:15px;margin-bottom:0;">
                <papertitle><strong>Cross-domain Imitation from Observations</strong></papertitle>, ICML '21 Oral
              </p>
              <p style="font-size:13px;margin-bottom:0;">Dripta Raychaudhuri*, <strong>Sujoy Paul</strong>*, Jeroen van Baar, Amit Roy-Chowdhury</p>
              <a style="font-size:13px" href="https://arxiv.org/pdf/2105.10037.pdf" target="_blank">paper </a> |
              <a style="font-size:13px" href="https://driptarc.github.io/xdio.html" target="_blank"> page </a> 
              <br> <br>
            </td>

            <td style="padding:10px;width:100%;vertical-align:baseline">
              <p style="font-size:15px;margin-bottom:0;">
                <papertitle><strong>Unsupervised Multi-source Domain Adaptation Without Access to Source Data</strong></papertitle>, CVPR '21 Oral
              </p>
              <p style="font-size:13px;margin-bottom:0;">Miraj Ahmed*, Dripta Raychaudhuri*, <strong>Sujoy Paul</strong>*, Samet Oymak, Amit Roy-Chowdhury</p>
              <a style="font-size:13px" href="https://arxiv.org/pdf/2104.01845.pdf" target="_blank">paper </a> |
              <a style="font-size:13px" href="https://github.com/driptaRC/DECISION" target="_blank">code </a>
              <!-- <a style="font-size:13px" href="" target="_blank"> code </a>  -->
              <!--<p>
                Unsupervised and Weakly-supervised adaptation in a single framework. Obtains close to full-supervision performace with very weak supervision. 
              </p>-->
              <br> <br>
            </td>

            <td style="padding:10px;width:100%;vertical-align:baseline">
              <p style="font-size:15px;margin-bottom:0;">
                <papertitle><strong>Adversarial Knowledge Transfer from Unlabeled Data</strong></papertitle>, ACM-MM '20
              </p>
              <p style="font-size:13px;margin-bottom:0;">Akash Gupta, Rameswar Panda, <strong>Sujoy Paul</strong>, Jianming Zhang, Amit Roy-Chowdhury</p>
              <a style="font-size:13px" href="https://arxiv.org/pdf/2008.05746.pdf" target="_blank">paper </a> |
              <a style="font-size:13px" href="https://github.com/agupt013/akt" target="_blank"> code </a> |
              <a style="font-size:13px" href="https://akashagupta.com/akt.html" target="_blank"> page </a> 
              <!--<p>
                Unsupervised and Weakly-supervised adaptation in a single framework. Obtains close to full-supervision performace with very weak supervision. 
              </p>-->
              <br> <br>
            </td>

            <td style="padding:10px;width:100%;vertical-align:baseline">
              <p style="font-size:15px;margin-bottom:0;">
                <papertitle><strong>Domain Adaptive Semantic Segmentation Using Weak Labels</strong></papertitle>, ECCV '20
              </p>
              <p style="font-size:13px;margin-bottom:0;"><strong>Sujoy Paul</strong>, Yi-Hsuan Tsai, Samuel Schulter, Amit Roy-Chowdhury, Manmohan Chandraker</p>
              <a style="font-size:13px" href="https://arxiv.org/pdf/2007.15176.pdf" target="_blank">paper </a> |
              <a style="font-size:13px" href="https://www.youtube.com/watch?v=pSQM8ViMkVg" target="_blank"> short video </a> | 
              <a style="font-size:13px" href="https://www.youtube.com/watch?v=1ZKbZj8it-A" target="_blank"> long video </a> |
              <a style="font-size:13px" href="http://www.nec-labs.com/~mas/WeakSegDA/" target="_blank"> page </a>
              <!--<p>
                Unsupervised and Weakly-supervised adaptation in a single framework. Obtains close to full-supervision performace with very weak supervision. 
              </p>-->
              <br> <br>
            </td>

            <td style="padding:10px;width:100%;vertical-align:middle">
              <p style="font-size:15px;margin-bottom:0;">
                <papertitle><strong>Learning from Trajectories via Subgoal Discovery</strong></papertitle>, NeurIPS '19
              </p>
              <p style="font-size:13px;margin-bottom:0;"><strong>Sujoy Paul</strong>, Jeroen van Baar, Amit Roy-Chowdhury</p>
              <a href="https://arxiv.org/pdf/1911.07224.pdf" target="_blank"> paper </a> | 
              <a href="https://github.com/sujoyp/subgoal-discovery" target="_blank"> code </a>
              <!--<p>
                Learned subgoals from expert demos and used them as rewards in RL to perform better than the expert.
              </p>-->
              <br> <br>
            </td>

            <td style="padding:10px;width:100%;vertical-align:middle">
              <p style="font-size:14.2px;margin-bottom:0;">
                <papertitle><strong>Weakly Supervised Video Moment Retrieval From Text Queries</strong></papertitle>, CVPR '19
              </p>
              <p style="font-size:13px;margin-bottom:0;">Niluthpol Mithun*, <strong>Sujoy Paul*</strong>, Amit Roy-Chowdhury</p>
              <a href="https://arxiv.org/pdf/1904.03282.pdf" target="_blank"> paper </a> | 
              <a href="https://github.com/niluthpol/weak_supervised_video_moment" target="_blank"> code </a>
              <!--<p>
                Learn the task of retriveing moments from a video relevant to a text query using just video level annotation, i.e., no temporal annotation.
              </p>-->
              <br> <br>
            </td>

            <!--<td style="padding:10px;width:100%;vertical-align:middle">
              <a style="font-size:15px;margin-bottom:0;">
                <papertitle><strong>Trajectory-based Learning for Ball-in-Maze Games</strong></papertitle>
              </a>
              <br>
              <p style="font-size:13px;margin-bottom:0;"><strong>Sujoy Paul</strong>, Jeroen van Baar</p>
              <em>NeurIPS-Workshop 2018  </em>
              <a href="https://arxiv.org/pdf/1811.11441.pdf" target="_blank">[Paper]</a>
              <p>
                Using the simulator as the model to generate demos via random shooting makes RL converge faster.
              </p>
            </td>-->

            <td style="padding:10px;width:100%;vertical-align:middle">
              <p style="font-size:14.2px;margin-bottom:0;">
                <papertitle><strong>Context-Aware Query Selection for Active Learning in Event Recognition</strong></papertitle>, PAMI '18
              </p>
              <p style="font-size:13px;margin-bottom:0;">Mahmudul Hasan*, <strong>Sujoy Paul*</strong>, Anastasios I. Mourikis, Amit Roy-Chowdhury</p>
              <a href="https://arxiv.org/pdf/1904.04406.pdf" target="_blank"> paper </a>
              <!--<p>
                Using context in active learning in budget-constrained scenarios.
              </p>-->
              <br> <br>
            </td>

            <td style="padding:10px;width:110%;vertical-align:middle">
              <p style="font-size:14.2px;margin-bottom:0;">
                <papertitle><strong>W-TALC: Weakly-supervised Temporal Activity Localization and Classification</strong></papertitle>, ECCV '18
              </p>
              <p style="font-size:13px;margin-bottom:0;"><strong>Sujoy Paul</strong>, Sourya Roy, Amit Roy-Chowdhury</p>
              <a href="https://arxiv.org/pdf/1807.10418.pdf" target="_blank"> paper </a> | 
              <a href="https://github.com/sujoyp/wtalc-pytorch" target="_blank"> code </a>
              <!--<p>
                Action detection in videos with only video-level weak labels, i.e., no temporal annotations.
              </p>-->
              <br> <br>
            </td>

            <td style="padding:10px;width:100%;vertical-align:middle">
              <p style="font-size:14.2px;margin-bottom:0;">
                <papertitle><strong>Exploiting Transitivity for Learning Person Re-identification Models on a Budget</strong></papertitle>, CVPR '18
              </p>
              <p style="font-size:13px;margin-bottom:0;">Sourya Roy, <strong>Sujoy Paul</strong>, Neal E. Young, Amit Roy-Chowdhury</p>
              <a href="https://openaccess.thecvf.com/content_cvpr_2018/CameraReady/4066.pdf" target="_blank"> paper </a> | 
              <a href="https://github.com/Video-Computing-Group/research-code/tree/master/CVPR_demo" target="_blank"> code </a>
              <!--<p>
                Using transtivity in multiple bi-partite graphs to reduce manual annotation for person re-id, yet achieving same state-of-the-art performance.
              </p>-->
              <br> <br>
            </td>

            <td style="padding:10px;width:100%;vertical-align:middle">
              <p style="font-size:14.2px;margin-bottom:0;">
                <papertitle><strong>Non-Uniform Subset Selection for Active Learning in Structured Data</strong></papertitle>, CVPR '17
              </p>
              <p style="font-size:13px;margin-bottom:0;"><strong>Sujoy Paul</strong>, Sourya Roy, Amit Roy-Chowdhury</p>
              <a href="https://intra.ece.ucr.edu/~supaul/Webpage_files/CVPR2017_1.pdf" target="_blank"> paper </a> |
              <a href="https://github.com/sujoyp/context-active-learning" target="_blank"> code </a>
              <!--<p>
                Using context information between data points to reduce manual labeling in active learning, in a general framework and can be applied to a wide range of applications. 
              </p>-->
              <br> <br>
            </td>

            <td style="padding:10px;width:100%;vertical-align:middle">
              <p style="font-size:15px;margin-bottom:0;">
                <papertitle><strong>Online Adaptation for Joint Scene and Object Classification</strong></papertitle>, ECCV '16
              </p>
              <p style="font-size:13px;margin-bottom:0;">Jawad H. Bappy, <strong>Sujoy Paul</strong>, Amit K. Roy-Chowdhury</p>
              <a href="https://intra.ece.ucr.edu/~supaul/Webpage_files/ECCV2016.pdf" target="_blank"> paper </a>
              <!--<p>
                Using context information in joint scene-object graphs to reduce manual annotation.
              </p>-->
              <br> <br>
            </td>


        

      </section>
      <footer>
        <p style="text-align:left;"><small>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp<a href="https://creativecommons.org/licenses/by-sa/3.0/">&#169;</a></small></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
  </body>
</html>
